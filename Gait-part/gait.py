# -*- coding: utf-8 -*-
"""Gait.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18WIzb6GSvrIIzoqgCmCqQvbmTTJzVLNA
"""

# main libraries
import tensorflow as tf
from tensorflow.keras import Sequential

from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization
from tensorflow.keras.optimizers import Adam
print('version of tensorflow :',tf.__version__)

# supporting libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold
import os
from skimage import data, color
from skimage.transform import rescale, resize, downscale_local_mean
import matplotlib.image as mpimg

# for confusion matrix plotting
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix,confusion_matrix

def create_dataframe(path,arr,label):
   for fil in os.listdir(path):
     link=path+fil
     img=mpimg.imread(link)
     img=resize(img,(28,28,1),anti_aliasing=True)
     img=img.reshape(784)
     arr.append(img)
   xx=np.ones(len(arr))*label
   arr=pd.DataFrame(arr)
   xx=pd.DataFrame({'label':xx})
   arr=pd.concat([xx,arr],axis=1)
   return arr

A=[]
A=create_dataframe('/content/drive/MyDrive/Dataset/A/',A,0)
type(A)

B=[]
B=create_dataframe('/content/drive/MyDrive/Dataset/B/',B,1)
type(B)

C=[]
C=create_dataframe('/content/drive/MyDrive/Dataset/C/',C,2)
type(C)

D=[]
D=create_dataframe('/content/drive/MyDrive/Dataset/D/',D,3)

len(A),len(B),len(C),len(D)

tr1=A.drop('label',1)
ts1=A['label']

X_train,X_test,y_train,y_test=train_test_split(tr1,ts1,test_size=0.2,random_state=0)
y_train=pd.DataFrame(y_train)
y_test=pd.DataFrame(y_test)

tr1=B.drop('label',1)
ts1=B['label']
x,xx,y,yy=train_test_split(tr1,ts1,test_size=0.2,random_state=0)
X_train=pd.concat([X_train,x],axis=0)
X_test=pd.concat([X_test,xx],axis=0)
y=pd.DataFrame(y)
yy=pd.DataFrame(yy)
y_train=pd.concat([y_train,y],axis=0)
y_test=pd.concat([y_test,yy],axis=0)

tr1=C.drop('label',1)
ts1=C['label']
x,xx,y,yy=train_test_split(tr1,ts1,test_size=0.2,random_state=0)
X_train=pd.concat([X_train,x],axis=0)
X_test=pd.concat([X_test,xx],axis=0)
y=pd.DataFrame(y)
yy=pd.DataFrame(yy)
y_train=pd.concat([y_train,y],axis=0)
y_test=pd.concat([y_test,yy],axis=0)


tr1=D.drop('label',1)
ts1=D['label']
x,xx,y,yy=train_test_split(tr1,ts1,test_size=0.2,random_state=0)
X_train=pd.concat([X_train,x],axis=0)
X_test=pd.concat([X_test,xx],axis=0)
y=pd.DataFrame(y)
yy=pd.DataFrame(yy)
y_train=pd.concat([y_train,y],axis=0)
y_test=pd.concat([y_test,yy],axis=0)

X_train.info()
print(len(X_train))

subject=['A','B','C','D']

plt.title('train images')
plt.pie(y_train['label'].value_counts().values,labels=subject)
plt.show()

plt.title('test images')
plt.pie(y_test['label'].value_counts().values,labels=subject)
plt.show()

train=pd.concat([y_train,X_train],axis=1)
test=pd.concat([y_test,X_test],axis=1)

train=train.sample(frac=1)
test=test.sample(frac=1)

len(train),len(test)

X_train=train.drop('label',1)
y_train=train['label']
X_test=test.drop('label',1)
y_test=test['label']

X_train=X_train.to_numpy()
y_train=y_train.to_numpy()
X_test=X_test.to_numpy()
y_test=y_test.to_numpy()
type(y_train[0]),type(y_test[0])

y_train=y_train.astype('int64')
y_test=y_test.astype('int64')
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

def best_SVC(X,y):
    svc_model = SVC()
    param_dic = {'C':[1,10,100],
                'gamma':[0.001,0.005,0.01]}
    clf = GridSearchCV(svc_model, param_dic, n_jobs=-1)
    clf.fit(X, y)
    print("Best parameters: ", clf.best_params_)
    return clf.best_estimator_

from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
pca = PCA(n_components = 4)
pca.fit(X_train)
reduced_X_train, reduced_X_test = pca.transform(X_train), pca.transform(X_test)

best_model = best_SVC(reduced_X_train,y_train)
predictions = best_model.predict(reduced_X_test)
print(accuracy_score(y_test, predictions))

from sklearn.metrics import classification_report
print(classification_report(y_test, predictions, target_names=subject))