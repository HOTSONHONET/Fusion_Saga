# -*- coding: utf-8 -*-
"""Gait.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18WIzb6GSvrIIzoqgCmCqQvbmTTJzVLNA
"""

# main libraries
import tensorflow as tf
from tensorflow.keras import Sequential

from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization
from tensorflow.keras.optimizers import Adam
print('version of tensorflow :',tf.__version__)

# supporting libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold
import os
from skimage import data, color
from skimage.transform import rescale, resize, downscale_local_mean
import matplotlib.image as mpimg

# for confusion matrix plotting
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix,confusion_matrix

def create_dataframe(path,arr,label):
   for fil in os.listdir(path):
     link=path+fil
     img=mpimg.imread(link)
     img=resize(img,(28,28,1),anti_aliasing=True)
     img=img.reshape(784)
     arr.append(img)
   xx=np.ones(len(arr))*label
   arr=pd.DataFrame(arr)
   xx=pd.DataFrame({'label':xx})
   arr=pd.concat([xx,arr],axis=1)
   return arr

import cv2
def create_fdataframe(path,arr,label):
   for fil in os.listdir(path):
     link=path+fil
     img=mpimg.imread(link)
     grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
     (thresh, bnw) = cv2.threshold(grayImage, 127, 255, cv2.THRESH_BINARY)
     bnw=resize(bnw,(28,28,1),anti_aliasing=True)
     bnw=bnw.reshape(784)
     arr.append(bnw)
   xx=np.ones(len(arr))*label
   arr=pd.DataFrame(arr)
   xx=pd.DataFrame({'label':xx})
   #arr=pd.concat([xx,arr],axis=1)
   return arr

AG=[]
AG=create_dataframe('/content/drive/MyDrive/Gait-dataset/Train/A/',AG,0)
print(type(AG))
AG.info()

Af=[]
Af=create_fdataframe('/content/drive/MyDrive/Face-dataset/Train/A/',Af,0)
print(type(Af))
Af.info()

A= pd.concat([AG,Af],axis=1)
A.info()

BG=[]
BG=create_dataframe('/content/drive/MyDrive/Gait-dataset/Train/B/',BG,1)
type(BG)
BG.info()

Bf=[]
Bf=create_fdataframe('/content/drive/MyDrive/Face-dataset/Train/B/',Bf,1)
print(type(Bf))
Bf.info()

B= pd.concat([BG,Bf],axis=1)
B.info()

CG=[]
CG=create_dataframe('/content/drive/MyDrive/Gait-dataset/Train/C/',CG,2)
type(CG)
CG.info()

Cf=[]
Cf=create_fdataframe('/content/drive/MyDrive/Face-dataset/Train/C/',Cf,2)
print(type(Cf))
Cf.info()

C= pd.concat([CG,Cf],axis=1)
C.info()

DG=[]
DG=create_dataframe('/content/drive/MyDrive/Gait-dataset/Train/D/',DG,3)
DG.info()

Df=[]
Df=create_fdataframe('/content/drive/MyDrive/Face-dataset/Train/D/',Df,3)
print(type(Df))
Df.info()

D= pd.concat([DG,Df],axis=1)
D.info()

len(A),len(B),len(C),len(D)

tr1=A.drop('label',1)
ts1=A['label']
X_A,y_A= tr1,ts1
y_A=pd.DataFrame(y_A)
print(len(X_A),len(y_A))

tr1=B.drop('label',1)
ts1=B['label']
X_B,y_B= tr1,ts1
y_B=pd.DataFrame(y_B)
print(len(X_B),len(y_B))

tr1=C.drop('label',1)
ts1=C['label']
y_C= pd.DataFrame(ts1)
X_C= tr1
print(len(X_C),len(y_C))

tr1=D.drop('label',1)
ts1=D['label']
y_D= pd.DataFrame(ts1)
X_D= tr1
print(len(X_D),len(y_D))

X_train= pd.concat([X_A,X_B,X_C,X_D],axis=0)
y_train= pd.concat([y_A,y_B,y_C,y_D],axis=0)

print(len(X_train),len(y_train))

subject=['A','B','C','D']

"""Test Dataframe Formation

"""

AGT= []
AGT= create_dataframe('/content/drive/MyDrive/Gait-dataset/Test/A/',AGT,0)
type(AGT)
AGT.info()

Aft=[]
Aft=create_fdataframe('/content/drive/MyDrive/Face-dataset/Test/A/',Aft,0)
Aft.info()

AT= pd.concat([AGT,Aft],axis=1)
AT.info()

BGT= []
BGT= create_dataframe('/content/drive/MyDrive/Gait-dataset/Test/B/',BGT,1)
type(BGT)
BGT.info()

Bft=[]
Bft=create_fdataframe('/content/drive/MyDrive/Face-dataset/Test/B/',Bft,1)
Bft.info()

BT= pd.concat([BGT,Bft],axis=1)
BT.info()

CGT= []
CGT= create_dataframe('/content/drive/MyDrive/Gait-dataset/Test/C/',CGT,2)
type(CGT)
CGT.info()

Cft=[]
Cft=create_fdataframe('/content/drive/MyDrive/Face-dataset/Test/C/',Cft,2)
Cft.info()

CT= pd.concat([CGT,Cft],axis=1)
CT.info()

DGT= []
DGT= create_dataframe('/content/drive/MyDrive/Gait-dataset/Test/D/',DGT,3)
type(DGT)
DGT.info()

Dft=[]
Dft=create_fdataframe('/content/drive/MyDrive/Face-dataset/Test/D/',Dft,3)
Dft.info()

DT= pd.concat([DGT,Dft],axis=1)
DT.info()

tr1=AT.drop('label',1)
ts1=AT['label']
X_AT,y_AT= tr1,ts1
y_AT=pd.DataFrame(y_AT)
print(len(X_AT),len(y_AT))

tr1=BT.drop('label',1)
ts1=BT['label']
X_BT,y_BT= tr1,ts1
y_BT=pd.DataFrame(y_BT)
print(len(X_BT),len(y_BT))

tr1=CT.drop('label',1)
ts1=CT['label']
X_CT,y_CT= tr1,ts1
y_CT=pd.DataFrame(y_CT)
print(len(X_CT),len(y_CT))

tr1=DT.drop('label',1)
ts1=DT['label']
X_DT,y_DT= tr1,ts1
y_DT=pd.DataFrame(y_DT)
print(len(X_DT),len(y_DT))

X_test= pd.concat([X_AT,X_BT,X_CT,X_DT],axis=0)
y_test=pd.concat([y_AT,y_BT,y_CT,y_DT],axis=0)
print(len(X_test),len(y_test))

plt.title('train images')
plt.pie(y_train['label'].value_counts().values,labels=subject)
plt.show()

plt.title('test images')
plt.pie(y_test['label'].value_counts().values,labels=subject)
plt.show()

train= pd.concat([X_train,y_train],axis=1)
test= pd.concat([X_test,y_test],axis=1)

train=train.sample(frac=1)
test=test.sample(frac=1)

len(train),len(test)

X_train=train.drop('label',1)
y_train=train['label']
X_test=test.drop('label',1)
y_test=test['label']

X_train=X_train.to_numpy()
y_train=y_train.to_numpy()
X_test=X_test.to_numpy()
y_test=y_test.to_numpy()
type(y_train[0]),type(y_test[0])

y_train=y_train.astype('int64')
y_test=y_test.astype('int64')
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

def best_SVC(X,y):
    svc_model = SVC()
    param_dic = {'C':[1,10,100],
                'gamma':[0.001,0.005,0.01]}
    clf = GridSearchCV(svc_model, param_dic, n_jobs=-1)
    clf.fit(X, y)
    print("Best parameters: ", clf.best_params_)
    return clf.best_estimator_

from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
pca = PCA(n_components = 4)
pca.fit(X_train)
reduced_X_train, reduced_X_test = pca.transform(X_train), pca.transform(X_test)

best_model = best_SVC(reduced_X_train,y_train)
predictions = best_model.predict(reduced_X_test)
print(accuracy_score(y_test, predictions))

from sklearn.metrics import classification_report
print(classification_report(y_test, predictions, target_names=subject))